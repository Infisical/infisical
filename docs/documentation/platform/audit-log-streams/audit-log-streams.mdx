---
title: "Audit Log Streams"
description: "Learn how to stream Infisical Audit Logs to external logging providers."
---

<Info>
    Audit log streams is a paid feature.

    If you're using Infisical Cloud, then it is available under the **Enterprise Tier**. If you're self-hosting Infisical,
    then you should contact team@infisical.com to purchase an enterprise license to use it.
</Info>

Infisical Audit Log Streaming enables you to transmit your organization's Audit Logs to external logging providers for monitoring and analysis.

The logs are formatted in JSON, requiring your logging provider to support JSON-based log parsing.


## Overview

<Steps>
    <Step title="Navigate to Organization Settings in your sidebar." />
    <Step title="Select Audit Log Streams Tab.">
				![stream create](/images/platform/audit-log-streams/stream-create.png)
		</Step>
		<Step title="Click on Create">
		 ![stream create](/images/platform/audit-log-streams/stream-inputs.png)

		 Provide the following values
		 <ParamField path="Endpoint URL" type="string" required>
				The HTTPS endpoint URL of the logging provider that collects the JSON stream.
     </ParamField>
		 <ParamField path="Headers" type="string" >
				The HTTP headers for the logging provider for identification and authentication.
     </ParamField>
		</Step>
</Steps>

![stream listt](/images/platform/audit-log-streams/stream-list.png)
Your Audit Logs are now ready to be streamed.

## Example Providers

### Better Stack

<Steps>
    <Step title="Select Connect Source">
				![better stack connect source](/images/platform/audit-log-streams/betterstack-create-source.png)
		</Step>
    <Step title="Provide a name and select platform"/>
   <Step title="Provide Audit Log Stream inputs">
				![better stack connect](/images/platform/audit-log-streams/betterstack-source-details.png)

				1. Copy the **endpoint** from Better Stack to the **Endpoint URL** field.
				3. Create a new header with key **Authorization** and set the value as **Bearer \<source token from betterstack\>**.
		</Step>
</Steps>

### Azure Log Analytics (for Microsoft Sentinel)

<Warning>
    After setting up all of the Azure resources it may take 10 - 20 minutes for logs to start streaming due to the nature of Azure's platform.
</Warning>

<Steps>
    <Step title="Create a Data Collection Endpoint">
        Navigate to [Data Collection Endpoints](https://portal.azure.com/#view/HubsExtension/BrowseResource.ReactView/resourceType/microsoft.insights%2Fdatacollectionendpoints) and click **Create**.

        ![azure create dce](/images/platform/audit-log-streams/azure-create-dce.png)

        Configure your Data Collection Endpoint by providing an **Endpoint Name**, **Subscription**, and a **Resource group**. Then click **Review + Create**.

        ![azure configure dce](/images/platform/audit-log-streams/azure-configure-dce.png)

        After you create a Data Collection Endpoint it may take a few minutes to show up in the list. Once it does, click on it and copy the **Logs Ingestion** URL. Save this URL for later steps.

        ![azure dce url](/images/platform/audit-log-streams/azure-dce-url.png)
    </Step>
    <Step title="Create a Log Analytics Workspace">
        <Info>
            If you already have a Log Analytics Workspace you may skip this step.
        </Info>

        Navigate to [Log Analytics Workspaces](https://portal.azure.com/#browse/Microsoft.OperationalInsights%2Fworkspaces) and click **Create**.

        ![azure create law](/images/platform/audit-log-streams/azure-create-law.png)

        Configure your Log Analytics Workspace by providing a **Subscription**, **Resource group**, and a **Name**. Then click **Review + Create**.

        ![azure configure law](/images/platform/audit-log-streams/azure-configure-law.png)

        After you create a workspace and wait for it to finish deploying, you'll see a screen similar to the one in the image below. Click on **Go to resource** to enter your Log Analytics Workspace.

        ![azure go to resource](/images/platform/audit-log-streams/azure-go-to-resource.png)
		</Step>
    <Step title="Create a Custom Log Table">
        In your Log Analytics Workspace, navigate to **Tables** and click **Create**. From the dropdown select **New custom log (DCR-based)**.

        ![azure new table](/images/platform/audit-log-streams/azure-new-table.png)

        Configure your Custom Log Table by providing a **Table name** (recommended: `InfisicalLogs`) and the **Data collection endpoint** created in Step 1. Also create a new **Data collection rule** as shown in the image below. Then click **Next**.

        ![azure configure table](/images/platform/audit-log-streams/azure-configure-table.png)

        On the **Schema and transformation** page you'll be asked to upload a **Log Sample**. Use the following sample (inside of a .json file):

        ```json
        {
          "id": "00000000-0000-0000-0000-000000000000",
          "actor": "user",
          "actorMetadata": {
            "email": "user@example.com",
            "userId": "00000000-0000-0000-0000-000000000000",
            "username": "user@example.com"
          },
          "ipAddress": "0.0.0.0",
          "userAgent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36",
          "userAgentType": "web",
          "eventType": "get-secrets",
          "eventMetadata": {},
          "projectName": "MyProject",
          "orgId": "00000000-0000-0000-0000-000000000000",
          "projectId": "00000000-0000-0000-0000-000000000000",
          "TimeGenerated": "2025-01-01T00:00:00.000Z"
        }
        ```

        You may optionally add **Transformations** to further destructure the data. Here's an example transformation that de-structures actor email and userId:

        ```
        source
        | extend
            ActorEmail = tostring(actorMetadata.email),
            ActorUserId = tostring(actorMetadata.userId)
        ```

        On the final step click **Create**.

        <Warning>
            It may take a few minutes for your Custom Log Table to be created and shown as part of Tables.
        </Warning>
		</Step>
    <Step title="Obtain Data Collection Rule Immutable ID">
        Now that you've created a Data Collection Rule alongside your Custom Log Table, you need its **Immutable ID**.

        Navigate to [Data collection rules](https://portal.azure.com/#view/HubsExtension/BrowseResource.ReactView/resourceType/microsoft.insights%2Fdatacollectionrules) and click on your new DCR. Copy the **Immutable ID** for the next step.

        ![azure dcr](/images/platform/audit-log-streams/azure-dcr.png)
		</Step>
    <Step title="Provide Audit Log Stream Inputs">
        Back on Infisical, create a new **Audit Log Stream** with the following inputs:

        **Endpoint URL:**
        ```
        <data-collection-endpoint-url>/dataCollectionRules/<data-collection-rule-id>/streams/Custom-<custom-log-table-name>_CL?api-version=2023-01-01
        ```

        - **data-collection-endpoint-url:** Obtained from Step 1
        - **data-collection-rule-id:** Obtained from Step 4
        - **custom-log-table-name:** Defined in Step 3

        **Headers:**
        - **Authorization:** `Bearer <azure-iam-jwt>`

        ![azure create als](/images/platform/audit-log-streams/azure-create-als.png)

        <Warning>
            The token used in the authorization header must have the **Monitoring Metrics Publisher** role assigned on the **Data Collection Rule** created in Step 3. [See Microsoft Guide](https://learn.microsoft.com/en-us/azure/azure-monitor/logs/tutorial-logs-ingestion-portal#assign-permissions-to-the-dcr).
        </Warning>
		</Step>
</Steps>

### Datadog

<Steps>
    <Step title="Navigate to API Keys section">
				![api key create](/images/platform/audit-log-streams/datadog-api-sidebar.png)
		</Step>
    <Step title="Select New Key and provide a key name">
				![api key form](/images/platform/audit-log-streams/data-create-api-key.png)
				![api key form](/images/platform/audit-log-streams/data-dog-api-key.png)
		</Step>
   <Step title="Find your Datadog region specific logging endpoint.">
				![datadog url](/images/platform/audit-log-streams/datadog-logging-endpoint.png)

				1. Navigate to the [Datadog Send Logs API documentation](https://docs.datadoghq.com/api/latest/logs/?code-lang=curl&site=us5#send-logs).
				2. Pick your Datadog account region.
				3. Obtain your Datadog logging endpoint URL.
	 </Step>
   <Step title="Provide audit log stream inputs">
				![datadog api key details](/images/platform/audit-log-streams/datadog-source-details.png)

				1. Copy the **logging endpoint** from Datadog to the **Endpoint URL** field.
				2. Copy the **API Key** from previous step
				3. Create a new header with key **DD-API-KEY** and set the value as **API Key**.
		</Step>
</Steps>

## Audit Log Stream Data

Each log entry sent to the external logging provider will follow the same structure.

### Example Log Entry

```created-secret.json
{
  "id": "7dc1713b-d787-4147-9e21-770be01cc992",
  "actor": "user",
  "actorMetadata": {
    "email": "example@infisical.com",
    "userId": "7383b701-d83f-45c0-acb4-04e138b987ab",
    "username": "example@infisical.com"
  },
  "ipAddress": "127.0.0.1",
  "eventType": "create-secret",
  "eventMetadata": {
    "secretId": "3e5c796e-6599-4181-8dca-51133bb3acd0",
    "secretKey": "TEST-SECRET",
    "secretPath": "/",
    "environment": "dev",
    "secretVersion": 1
  },
  "userAgent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
  "userAgentType": "web",
  "expiresAt": "2025-01-18T01:11:25.552Z",
  "createdAt": "2025-01-15T01:11:25.552Z",
  "updatedAt": "2025-01-15T01:11:25.552Z",
  "orgId": "785649f1-ff4b-4ef9-a40a-9b9878e46e57",
  "projectId": "09bfcc01-0917-4bea-9c7a-2d320584d5b1",
  "projectName": "example-project"
}
```

### Audit Logs Structure
<ParamField path="id" type="string" required>
  The unique identifier for the log entry.
</ParamField>

<ParamField path="actor" type="platform | user | service | identity | scimClient | unknownUser" required>
  The entity responsible for performing or causing the event; this can be a user or service.
</ParamField>

<ParamField path="actorMetadata" type="object" required>
  The metadata associated with the actor. This varies based on the actor type.

  <Accordion title="User Metadata">
    This metadata is present when the `actor` field is set to `user`.

    <ParamField path="userId" type="string" required>
      The unique identifier for the actor.
    </ParamField>
    <ParamField path="email" type="string" required>
      The email address of the actor.
    </ParamField>
     <ParamField path="username" type="string" required>
      The username of the actor.
    </ParamField>
  </Accordion>

  <Accordion title="Identity Metadata">
    This metadata is present when the `actor` field is set to `identity`.

    <ParamField path="identityId" type="string" required>
      The unique identifier for the identity.
    </ParamField>
    <ParamField path="name" type="string" required>
      The name of the identity.
    </ParamField>
  </Accordion>

  <Accordion title="Service Token Metadata">
    This metadata is present when the `actor` field is set to `service`.

    <ParamField path="serviceId" type="string" required>
      The unique identifier for the service.
    </ParamField>
    <ParamField path="name" type="string" required>
      The name of the service.
    </ParamField>
  </Accordion>


  <Note>
    If the `actor` field is set to `platform`, `scimClient`, or `unknownUser`, the `actorMetadata` field will be an empty object.
  </Note>

</ParamField>

<ParamField path="ipAddress" type="string" required>
  The IP address of the actor.
</ParamField>

<ParamField path="eventType" type="string" required>
  The type of event that occurred. Below you can see a list of possible event types. More event types will be added in the future as we expand our audit logs further.

  `get-secrets`, `delete-secrets`, `get-secret`, `create-secret`, `update-secret`, `delete-secret`, `get-workspace-key`, `authorize-integration`, `update-integration-auth`, `unauthorize-integration`, `create-integration`, `delete-integration`, `add-trusted-ip`, `update-trusted-ip`, `delete-trusted-ip`, `create-service-token`, `delete-service-token`, `create-identity`, `update-identity`, `delete-identity`, `login-identity-universal-auth`, `add-identity-universal-auth`, `update-identity-universal-auth`, `get-identity-universal-auth`, `create-identity-universal-auth-client-secret`, `revoke-identity-universal-auth-client-secret`, `get-identity-universal-auth-client-secret`, `create-environment`, `update-environment`, `delete-environment`, `add-workspace-member`, `remove-workspace-member`, `create-folder`, `update-folder`, `delete-folder`, `create-webhook`, `update-webhook-status`, `delete-webhook`, `webhook-triggered`, `get-secret-imports`, `create-secret-import`, `update-secret-import`, `delete-secret-import`, `update-user-workspace-role`, `update-user-workspace-denied-permissions`, `create-certificate-authority`, `get-certificate-authority`, `update-certificate-authority`, `delete-certificate-authority`, `get-certificate-authority-csr`, `get-certificate-authority-cert`, `sign-intermediate`, `import-certificate-authority-cert`, `get-certificate-authority-crl`, `issue-cert`, `get-cert`, `delete-cert`, `revoke-cert`, `get-cert-body`, `create-pki-alert`, `get-pki-alert`, `update-pki-alert`, `delete-pki-alert`, `create-pki-collection`, `get-pki-collection`, `update-pki-collection`, `delete-pki-collection`, `get-pki-collection-items`, `add-pki-collection-item`, `delete-pki-collection-item`, `org-admin-accessed-project`, `create-certificate-template`, `update-certificate-template`, `delete-certificate-template`, `get-certificate-template`, `create-certificate-template-est-config`, `update-certificate-template-est-config`, `get-certificate-template-est-config`, `update-project-slack-config`, `get-project-slack-config`, `integration-synced`, `create-shared-secret`, `delete-shared-secret`, `read-shared-secret`.
</ParamField>

<ParamField path="eventMetadata" type="object" required>
  The metadata associated with the event. This varies based on the event type.
</ParamField>

<ParamField path="userAgent" type="string">
  The user agent of the actor, if applicable.
</ParamField>

<ParamField path="userAgentType" type="web | cli | k8-operator | terraform | other | InfisicalPythonSDK | InfisicalNodeSDK">
  The type of user agent.
</ParamField>

<ParamField path="expiresAt" type="string" required>
  The expiration date of the log entry. When this date is reached, the log entry will be deleted from Infisical.
</ParamField>

<ParamField path="createdAt" type="string" required>
  The creation date of the log entry.
</ParamField>

<ParamField path="updatedAt" type="string" required>
  The last update date of the log entry. This is unlikely to be out of sync with the `createdAt` field, as we do not update log entries after they've been created.
</ParamField>

<ParamField path="orgId" type="string" required>
  The unique identifier for the organization where the event occurred.
</ParamField>

<ParamField path="projectId" type="string">
  The unique identifier for the project where the event occurred.

  The `projectId` field will only be present if the event occurred at the project level, not the organization level.
</ParamField>

<ParamField path="projectName" type="string">
  The name of the project where the event occurred.

  The `projectName` field will only be present if the event occurred at the project level, not the organization level.
</ParamField>
